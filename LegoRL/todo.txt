TODO:
- [add]: nn.init?
- [add]: multi-reward support
- [add]: recurrent network support
- [add]: random seed
- [add]: What about train-eval modes?
- [infra]: Visualize Q(s, a) for Q-learning. Text on replays? what is the reward after all?
- [infra]: Episode plots: Q spread, Monte-Carlo V, V.
- [infra]: check plotly plotting. Alternative plots smoothing? With dispersion, min and max?
- [optimization]: test vectorized work with SumTree
- [add]: multi-gamma support
- [add]: several-envs-per-core test
- [add]: CEM
- [add]: decorrelator for timer-based environments
- [bug]: noisy linear does not work as an actor with deterministic envs.
- [infra]: visualization takes a lot of time warning
- [infra]: parallel visualization?