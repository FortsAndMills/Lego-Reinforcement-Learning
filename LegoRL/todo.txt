TODO:
- What about train-eval modes?
- V(s_0) plotting
- Visualize Q(s, a) for Q-learning
- graphviz scheme visualisation?
- Several runners tests.
- play test games each k-th frame and save animations to separate folder
- in parallel environments, draw several reward lines?
- alternative plots smoothing?
- check plotly plotting

- optimization (?): vectorized work with SumTree
- optimization: how to store references to same states in ReplayBuffer?

- bug (?): target network loading might happen before q_net loading
- bug: priorities are equal to loss. In DQN it is square root of loss.